{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Enriched Master Dataset\n",
    "\n",
    "This notebook reads the cleaned yearly CSV files and adds supplemental columns needed for analysis.\n",
    "\n",
    "**What this does:**\n",
    "- Reads all `cleaned_*.csv` files from `../data/cleaned/`\n",
    "- Adds supplemental columns (SEVIS_ID, IS_STEM, geographic mappings, etc.)\n",
    "- Outputs a single enriched master Parquet file\n",
    "\n",
    "**Supporting data required:**\n",
    "- DHS STEM CIP code list (2024)\n",
    "- CIP code to NSF subject field mapping\n",
    "- ZIP code to LMA mapping (quarterly, 2010-2024)\n",
    "- ZIP code to county mapping (quarterly, 2010-2024)\n",
    "- Working population by county (yearly, 2004-2023)\n",
    "\n",
    "**Run this once** after cleaning the data and before creating staging tables.\n",
    "\n",
    "**Expected runtime:** 10-30 minutes depending on your machine and data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-renv",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ renv library activated:\n",
      "  /Users/violet/Desktop/repos/OPT-observatory/renv/library/macos/R-4.5/aarch64-apple-darwin24.4.0\n",
      "\n",
      "✓ Library paths: 4 paths configured\n",
      "✓ duckdb package found\n"
     ]
    }
   ],
   "source": [
    "# Activate renv environment and set library paths\n",
    "renv_lib_path <- normalizePath(\"../renv/library/macos/R-4.5/aarch64-apple-darwin24.4.0\", mustWork=FALSE)\n",
    "\n",
    "if (dir.exists(renv_lib_path)) {\n",
    "  # Set library paths to use renv library first\n",
    "  .libPaths(c(renv_lib_path, .libPaths()))\n",
    "  cat(\"✓ renv library activated:\n",
    "\")\n",
    "  cat(sprintf(\"  %s\n",
    "\", renv_lib_path))\n",
    "  cat(sprintf(\"\n",
    "✓ Library paths: %d paths configured\n",
    "\", length(.libPaths())))\n",
    "  \n",
    "  # Verify duckdb is available\n",
    "  if (\"duckdb\" %in% rownames(installed.packages(lib.loc=renv_lib_path))) {\n",
    "    cat(\"✓ duckdb package found\n",
    "\")\n",
    "  } else {\n",
    "    warning(\"duckdb package not found in renv library\")\n",
    "  }\n",
    "} else {\n",
    "  warning(sprintf(\"renv library not found at: %s\", renv_lib_path))\n",
    "  cat(\"Attempting to activate renv...\n",
    "\")\n",
    "  if (file.exists(\"../renv.lock\")) {\n",
    "    if (!requireNamespace(\"renv\", quietly=TRUE)) {\n",
    "      install.packages(\"renv\", repos=\"https://cloud.r-project.org\")\n",
    "    }\n",
    "    renv::activate(\"..\")\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Input: ../data/cleaned/cleaned_*_all.csv\n",
      "  Output: ../data/sevis_f1_enriched_master.parquet\n",
      "  Supporting data: ../data/supporting\n"
     ]
    }
   ],
   "source": [
    "# ===== USER CONFIGURATION =====\n",
    "\n",
    "# Input paths\n",
    "RAW_DATA_PATH <- '../data/cleaned/cleaned_*_all.csv'\n",
    "SUPPORTING_DATA_DIR <- '../data/supporting'\n",
    "\n",
    "# Output path\n",
    "OUTPUT_PATH <- '../data/sevis_f1_enriched_master.parquet'\n",
    "\n",
    "# Supporting data files (update these paths as needed)\n",
    "DHS_STEM_LIST <- file.path(SUPPORTING_DATA_DIR, 'dhs_stem_cip_code_list_July2024.csv')\n",
    "CIP_TO_NSF_MAPPING <- file.path(SUPPORTING_DATA_DIR, 'cip_code_to_nsf_subject_field_mapping.csv')\n",
    "ZIP_LMA_MAPPING <- file.path(SUPPORTING_DATA_DIR, 'zip_county_lma_quarterly.csv')\n",
    "ZIP_COUNTY_CROSSWALK <- file.path(SUPPORTING_DATA_DIR, 'HUD_zip_code_to_county_crosswalk_2010-2024.csv')\n",
    "WORKING_POP_BY_COUNTY <- file.path(SUPPORTING_DATA_DIR, 'working_pop_by_county_fips_2004-2023.csv')\n",
    "\n",
    "cat(\"Configuration:\\n\")\n",
    "cat(sprintf(\"  Input: %s\\n\", RAW_DATA_PATH))\n",
    "cat(sprintf(\"  Output: %s\\n\", OUTPUT_PATH))\n",
    "cat(sprintf(\"  Supporting data: %s\\n\", SUPPORTING_DATA_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: DBI\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DuckDB connection established\n",
      "\n",
      "Checking supporting data files:\n",
      "  ✓ dhs_stem_cip_code_list_July2024.csv\n",
      "  ✓ cip_code_to_nsf_subject_field_mapping.csv\n",
      "  ✓ zip_county_lma_quarterly.csv\n",
      "  ✓ HUD_zip_code_to_county_crosswalk_2010-2024.csv\n",
      "  ✓ working_pop_by_county_fips_2004-2023.csv\n"
     ]
    }
   ],
   "source": [
    "library(duckdb)\n",
    "library(DBI)\n",
    "\n",
    "# Connect to DuckDB\n",
    "con <- dbConnect(duckdb::duckdb())\n",
    "\n",
    "cat(\"✓ DuckDB connection established\\n\")\n",
    "\n",
    "# Check that supporting data files exist\n",
    "required_files <- c(DHS_STEM_LIST, CIP_TO_NSF_MAPPING, ZIP_LMA_MAPPING, \n",
    "                    ZIP_COUNTY_CROSSWALK, WORKING_POP_BY_COUNTY)\n",
    "\n",
    "cat(\"\\nChecking supporting data files:\\n\")\n",
    "for (f in required_files) {\n",
    "  if (file.exists(f)) {\n",
    "    cat(sprintf(\"  ✓ %s\\n\", basename(f)))\n",
    "  } else {\n",
    "    cat(sprintf(\"  ✗ MISSING: %s\\n\", basename(f)))\n",
    "    stop(sprintf(\"Required file not found: %s\", f))\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create SEVIS_ID\n",
    "\n",
    "Unique identifier combining Year + Individual_Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 1: Creating SEVIS_ID ===\n",
      "Reading raw data and creating SEVIS_ID column...\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "\u001b[1m\u001b[33mError\u001b[39m in `duckdb_result()` at duckdb/R/dbSendQuery__duckdb_connection_character.R:16:3:\u001b[22m\n\u001b[33m!\u001b[39m Invalid Error: Conversion Error: CSV Error on Line: 178816\nOriginal Line: china,china,4/1/02,8/22/00,,f1,,4/4/1012,university of cincinnati,cincinnati,ohio,45221,11.0701,computer science,,,,,9/1/00,8/31/03,msc,jacksonville,fl,32224,,cpt,4/28/03,8/31/03,,,,,,full time,,996,9585,,,3000,,terminated,master's,135546,143554,2004,2004\nError when converting column \"VISA_EXPIRATION_DATE\". Could not convert string \"4/4/1012\" to 'DATE'\n\nColumn VISA_EXPIRATION_DATE is being converted as type DATE\nThis type was auto-detected from the CSV file.\nPossible solutions:\n* Override the type for this column manually by setting the type explicitly, e.g., types={'VISA_EXPIRATION_DATE': 'VARCHAR'}\n* Set the sample size to a larger value to enable the auto-detection to scan more values, e.g., sample_size=-1\n* Use a COPY statement to automatically derive types from an existing table.\n* Check whether the null string value is set correctly (e.g., nullstr = 'N/A')\n\n  file = ../data/cleaned/cleaned_2004_all.csv\n  delimiter = , (Auto-Detected)\n  quote = \" (Auto-Detected)\n  escape = \" (Auto-Detected)\n  new_line = \\n (Auto-Detected)\n  header = true (Auto-Detected)\n  skip_rows = 0 (Auto-Detected)\n  comment = (empty) (Auto-Detected)\n  strict_mode = true (Auto-Detected)\n  date_format = %m/%d/%y (Auto-Detected)\n  timestamp_format =  (Auto-Detected)\n  null_padding = 0\n  sample_size = 20480\n  ignore_errors = false\n  all_varchar = 0\n\n\n\u001b[34mℹ\u001b[39m Context: rapi_execute\n\u001b[34mℹ\u001b[39m Error type: INVALID\n\u001b[34mℹ\u001b[39m Raw message: Conversion Error: CSV Error on Line: 178816\nOriginal Line: china,china,4/1/02,8/22/00,,f1,,4/4/1012,university of cincinnati,cincinnati,ohio,45221,11.0701,computer science,,,,,9/1/00,8/31/03,msc,jacksonville,fl,32224,,cpt,4/28/03,8/31/03,,,,,,full time,,996,9585,,,3000,,terminated,master's,135546,143554,2004,2004\nError when converting column \"VISA_EXPIRATION_DATE\". Could not convert string \"4/4/1012\" to 'DATE'\n\nColumn VISA_EXPIRATION_DATE is being converted as type DATE\nThis type was auto-detected from the CSV file.\nPossible solutions:\n* Override the type for this column manually by setting the type explicitly, e.g., types={'VISA_EXPIRATION_DATE': 'VARCHAR'}\n* Set the sample size to a larger value to enable the auto-detection to scan more values, e.g., sample_size=-1\n* Use a COPY statement to automatically derive types from an existing table.\n* Check whether the null string value is set correctly (e.g., nullstr = 'N/A')\n\n  file = ../data/cleaned/cleaned_2004_all.csv\n  delimiter = , (Auto-Detected)\n  quote = \" (Auto-Detected)\n  escape = \" (Auto-Detected)\n  new_line = \\n (Auto-Detected)\n  header = true (Auto-Detected)\n  skip_rows = 0 (Auto-Detected)\n  comment = (empty) (Auto-Detected)\n  strict_mode = true (Auto-Detected)\n  date_format = %m/%d/%y (Auto-Detected)\n  timestamp_format =  (Auto-Detected)\n  null_padding = 0\n  sample_size = 20480\n  ignore_errors = false\n  all_varchar = 0\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1m\u001b[33mError\u001b[39m in `duckdb_result()` at duckdb/R/dbSendQuery__duckdb_connection_character.R:16:3:\u001b[22m\n\u001b[33m!\u001b[39m Invalid Error: Conversion Error: CSV Error on Line: 178816\nOriginal Line: china,china,4/1/02,8/22/00,,f1,,4/4/1012,university of cincinnati,cincinnati,ohio,45221,11.0701,computer science,,,,,9/1/00,8/31/03,msc,jacksonville,fl,32224,,cpt,4/28/03,8/31/03,,,,,,full time,,996,9585,,,3000,,terminated,master's,135546,143554,2004,2004\nError when converting column \"VISA_EXPIRATION_DATE\". Could not convert string \"4/4/1012\" to 'DATE'\n\nColumn VISA_EXPIRATION_DATE is being converted as type DATE\nThis type was auto-detected from the CSV file.\nPossible solutions:\n* Override the type for this column manually by setting the type explicitly, e.g., types={'VISA_EXPIRATION_DATE': 'VARCHAR'}\n* Set the sample size to a larger value to enable the auto-detection to scan more values, e.g., sample_size=-1\n* Use a COPY statement to automatically derive types from an existing table.\n* Check whether the null string value is set correctly (e.g., nullstr = 'N/A')\n\n  file = ../data/cleaned/cleaned_2004_all.csv\n  delimiter = , (Auto-Detected)\n  quote = \" (Auto-Detected)\n  escape = \" (Auto-Detected)\n  new_line = \\n (Auto-Detected)\n  header = true (Auto-Detected)\n  skip_rows = 0 (Auto-Detected)\n  comment = (empty) (Auto-Detected)\n  strict_mode = true (Auto-Detected)\n  date_format = %m/%d/%y (Auto-Detected)\n  timestamp_format =  (Auto-Detected)\n  null_padding = 0\n  sample_size = 20480\n  ignore_errors = false\n  all_varchar = 0\n\n\n\u001b[34mℹ\u001b[39m Context: rapi_execute\n\u001b[34mℹ\u001b[39m Error type: INVALID\n\u001b[34mℹ\u001b[39m Raw message: Conversion Error: CSV Error on Line: 178816\nOriginal Line: china,china,4/1/02,8/22/00,,f1,,4/4/1012,university of cincinnati,cincinnati,ohio,45221,11.0701,computer science,,,,,9/1/00,8/31/03,msc,jacksonville,fl,32224,,cpt,4/28/03,8/31/03,,,,,,full time,,996,9585,,,3000,,terminated,master's,135546,143554,2004,2004\nError when converting column \"VISA_EXPIRATION_DATE\". Could not convert string \"4/4/1012\" to 'DATE'\n\nColumn VISA_EXPIRATION_DATE is being converted as type DATE\nThis type was auto-detected from the CSV file.\nPossible solutions:\n* Override the type for this column manually by setting the type explicitly, e.g., types={'VISA_EXPIRATION_DATE': 'VARCHAR'}\n* Set the sample size to a larger value to enable the auto-detection to scan more values, e.g., sample_size=-1\n* Use a COPY statement to automatically derive types from an existing table.\n* Check whether the null string value is set correctly (e.g., nullstr = 'N/A')\n\n  file = ../data/cleaned/cleaned_2004_all.csv\n  delimiter = , (Auto-Detected)\n  quote = \" (Auto-Detected)\n  escape = \" (Auto-Detected)\n  new_line = \\n (Auto-Detected)\n  header = true (Auto-Detected)\n  skip_rows = 0 (Auto-Detected)\n  comment = (empty) (Auto-Detected)\n  strict_mode = true (Auto-Detected)\n  date_format = %m/%d/%y (Auto-Detected)\n  timestamp_format =  (Auto-Detected)\n  null_padding = 0\n  sample_size = 20480\n  ignore_errors = false\n  all_varchar = 0\n\nTraceback:\n",
      "1. dbExecute(con, query_sevis_id)   # at line 57 of file /private/var/folders/3r/fm67pndj58l3r5mfj16fw8km0000gn/T/Rtmp69p7Vs/renv-package-new-43b238249ab9/DBI/R/dbExecute.R",
      "2. dbSendStatement(conn, statement, ...)   # at line 4 of file /private/var/folders/3r/fm67pndj58l3r5mfj16fw8km0000gn/T/Rtmp69p7Vs/renv-package-new-43b238249ab9/DBI/R/dbExecute_DBIConnection_character.R",
      "3. dbSendStatement(conn, statement, ...)",
      "4. dbSendQuery(conn, statement, ...)   # at line 4 of file /private/var/folders/3r/fm67pndj58l3r5mfj16fw8km0000gn/T/Rtmp69p7Vs/renv-package-new-43b238249ab9/DBI/R/dbSendStatement_DBIConnection_character.R",
      "5. dbSendQuery(conn, statement, ...)",
      "6. .local(conn, statement, ...)",
      "7. duckdb_result(connection = conn, stmt_lst = stmt_lst, arrow = arrow)   # at line 16-20 of file /private/var/folders/3r/fm67pndj58l3r5mfj16fw8km0000gn/T/Rtmp8zMAme/renv-package-new-16a3a7de3bc46/duckdb/R/dbSendQuery__duckdb_connection_character.R",
      "8. duckdb_execute(res)   # at line 41 of file /private/var/folders/3r/fm67pndj58l3r5mfj16fw8km0000gn/T/Rtmp8zMAme/renv-package-new-16a3a7de3bc46/duckdb/R/Result.R",
      "9. rethrow_rapi_execute(res@stmt_lst$ref, duckdb_convert_opts_impl(res@connection@convert_opts, \n .     arrow = res@arrow))   # at line 49-52 of file /private/var/folders/3r/fm67pndj58l3r5mfj16fw8km0000gn/T/Rtmp8zMAme/renv-package-new-16a3a7de3bc46/duckdb/R/Result.R",
      "10. rlang::try_fetch(rapi_execute(stmt, convert_opts), error = function(e) {\n  .     rethrow_error_from_rapi(e, call)\n  . })   # at line 508-513 of file /private/var/folders/3r/fm67pndj58l3r5mfj16fw8km0000gn/T/Rtmp8zMAme/renv-package-new-16a3a7de3bc46/duckdb/R/rethrow-gen.R",
      "11. tryCatch(withCallingHandlers(expr, condition = function(cnd) {\n  .     {\n  .         .__handler_frame__. <- TRUE\n  .         .__setup_frame__. <- frame\n  .         if (inherits(cnd, \"message\")) {\n  .             except <- c(\"warning\", \"error\")\n  .         }\n  .         else if (inherits(cnd, \"warning\")) {\n  .             except <- \"error\"\n  .         }\n  .         else {\n  .             except <- \"\"\n  .         }\n  .     }\n  .     while (!is_null(cnd)) {\n  .         if (inherits(cnd, \"error\")) {\n  .             out <- handlers[[1L]](cnd)\n  .             if (!inherits(out, \"rlang_zap\")) \n  .                 throw(out)\n  .         }\n  .         inherit <- .subset2(.subset2(cnd, \"rlang\"), \"inherit\")\n  .         if (is_false(inherit)) {\n  .             return()\n  .         }\n  .         cnd <- .subset2(cnd, \"parent\")\n  .     }\n  . }), stackOverflowError = handlers[[1L]])",
      "12. tryCatchList(expr, classes, parentenv, handlers)",
      "13. tryCatchOne(expr, names, parentenv, handlers[[1L]])",
      "14. doTryCatch(return(expr), name, parentenv, handler)",
      "15. withCallingHandlers(expr, condition = function(cnd) {\n  .     {\n  .         .__handler_frame__. <- TRUE\n  .         .__setup_frame__. <- frame\n  .         if (inherits(cnd, \"message\")) {\n  .             except <- c(\"warning\", \"error\")\n  .         }\n  .         else if (inherits(cnd, \"warning\")) {\n  .             except <- \"error\"\n  .         }\n  .         else {\n  .             except <- \"\"\n  .         }\n  .     }\n  .     while (!is_null(cnd)) {\n  .         if (inherits(cnd, \"error\")) {\n  .             out <- handlers[[1L]](cnd)\n  .             if (!inherits(out, \"rlang_zap\")) \n  .                 throw(out)\n  .         }\n  .         inherit <- .subset2(.subset2(cnd, \"rlang\"), \"inherit\")\n  .         if (is_false(inherit)) {\n  .             return()\n  .         }\n  .         cnd <- .subset2(cnd, \"parent\")\n  .     }\n  . })",
      "16. rapi_execute(stmt, convert_opts)   # at line 508-513 of file /private/var/folders/3r/fm67pndj58l3r5mfj16fw8km0000gn/T/Rtmp8zMAme/renv-package-new-16a3a7de3bc46/duckdb/R/rethrow-gen.R",
      "17. (function (context, message, error_type = NULL, raw_message = NULL, \n  .     extra_info = NULL) \n  . {\n  .     fields <- list()\n  .     fields$context <- context\n  .     fields$error_type <- error_type\n  .     fields$raw_message <- raw_message\n  .     fields$extra_info <- extra_info\n  .     error_parts <- c(message, i = paste0(\"Context: \", context))\n  .     if (!is.null(error_type)) {\n  .         error_parts <- c(error_parts, i = paste0(\"Error type: \", \n  .             error_type))\n  .     }\n  .     if (!is.null(raw_message) && raw_message != message) {\n  .         error_parts <- c(error_parts, i = paste0(\"Raw message: \", \n  .             raw_message))\n  .     }\n  .     if (length(extra_info) > 0) {\n  .         info_text <- paste0(names(extra_info), \": \", extra_info)\n  .         names(info_text) <- rep_len(\"i\", length(info_text))\n  .         error_parts <- c(error_parts, info_text)\n  .     }\n  .     rlang::abort(error_parts, class = \"duckdb_error\", !!!fields)\n  . })(\"rapi_execute\", \"Invalid Error: Conversion Error: CSV Error on Line: 178816\\nOriginal Line: china,china,4/1/02,8/22/00,,f1,,4/4/1012,university of cincinnati,cincinnati,ohio,45221,11.0701,computer science,,,,,9/1/00,8/31/03,msc,jacksonville,fl,32224,,cpt,4/28/03,8/31/03,,,,,,full time,,996,9585,,,3000,,terminated,master's,135546,143554,2004,2004\\nError when converting column \\\"VISA_EXPIRATION_DATE\\\". Could not convert string \\\"4/4/1012\\\" to 'DATE'\\n\\nColumn VISA_EXPIRATION_DATE is being converted as type DATE\\nThis type was auto-detected from the CSV file.\\nPossible solutions:\\n* Override the type for this column manually by setting the type explicitly, e.g., types={'VISA_EXPIRATION_DATE': 'VARCHAR'}\\n* Set the sample size to a larger value to enable the auto-detection to scan more values, e.g., sample_size=-1\\n* Use a COPY statement to automatically derive types from an existing table.\\n* Check whether the null string value is set correctly (e.g., nullstr = 'N/A')\\n\\n  file = ../data/cleaned/cleaned_2004_all.csv\\n  delimiter = , (Auto-Detected)\\n  quote = \\\" (Auto-Detected)\\n  escape = \\\" (Auto-Detected)\\n  new_line = \\\\n (Auto-Detected)\\n  header = true (Auto-Detected)\\n  skip_rows = 0 (Auto-Detected)\\n  comment = (empty) (Auto-Detected)\\n  strict_mode = true (Auto-Detected)\\n  date_format = %m/%d/%y (Auto-Detected)\\n  timestamp_format =  (Auto-Detected)\\n  null_padding = 0\\n  sample_size = 20480\\n  ignore_errors = false\\n  all_varchar = 0\\n\\n\", \n  .     \"INVALID\", \"Conversion Error: CSV Error on Line: 178816\\nOriginal Line: china,china,4/1/02,8/22/00,,f1,,4/4/1012,university of cincinnati,cincinnati,ohio,45221,11.0701,computer science,,,,,9/1/00,8/31/03,msc,jacksonville,fl,32224,,cpt,4/28/03,8/31/03,,,,,,full time,,996,9585,,,3000,,terminated,master's,135546,143554,2004,2004\\nError when converting column \\\"VISA_EXPIRATION_DATE\\\". Could not convert string \\\"4/4/1012\\\" to 'DATE'\\n\\nColumn VISA_EXPIRATION_DATE is being converted as type DATE\\nThis type was auto-detected from the CSV file.\\nPossible solutions:\\n* Override the type for this column manually by setting the type explicitly, e.g., types={'VISA_EXPIRATION_DATE': 'VARCHAR'}\\n* Set the sample size to a larger value to enable the auto-detection to scan more values, e.g., sample_size=-1\\n* Use a COPY statement to automatically derive types from an existing table.\\n* Check whether the null string value is set correctly (e.g., nullstr = 'N/A')\\n\\n  file = ../data/cleaned/cleaned_2004_all.csv\\n  delimiter = , (Auto-Detected)\\n  quote = \\\" (Auto-Detected)\\n  escape = \\\" (Auto-Detected)\\n  new_line = \\\\n (Auto-Detected)\\n  header = true (Auto-Detected)\\n  skip_rows = 0 (Auto-Detected)\\n  comment = (empty) (Auto-Detected)\\n  strict_mode = true (Auto-Detected)\\n  date_format = %m/%d/%y (Auto-Detected)\\n  timestamp_format =  (Auto-Detected)\\n  null_padding = 0\\n  sample_size = 20480\\n  ignore_errors = false\\n  all_varchar = 0\\n\\n\", \n  .     list())   # at line 228 of file /private/var/folders/3r/fm67pndj58l3r5mfj16fw8km0000gn/T/Rtmp8zMAme/renv-package-new-16a3a7de3bc46/duckdb/R/cpp11.R",
      "18. rlang::abort(error_parts, class = \"duckdb_error\", !!!fields)   # at line 47 of file /private/var/folders/3r/fm67pndj58l3r5mfj16fw8km0000gn/T/Rtmp8zMAme/renv-package-new-16a3a7de3bc46/duckdb/R/duckdb.R",
      "19. signal_abort(cnd, .file)",
      "20. signalCondition(cnd)",
      "21. (function (cnd) \n  . {\n  .     {\n  .         .__handler_frame__. <- TRUE\n  .         .__setup_frame__. <- frame\n  .         if (inherits(cnd, \"message\")) {\n  .             except <- c(\"warning\", \"error\")\n  .         }\n  .         else if (inherits(cnd, \"warning\")) {\n  .             except <- \"error\"\n  .         }\n  .         else {\n  .             except <- \"\"\n  .         }\n  .     }\n  .     while (!is_null(cnd)) {\n  .         if (inherits(cnd, \"error\")) {\n  .             out <- handlers[[1L]](cnd)\n  .             if (!inherits(out, \"rlang_zap\")) \n  .                 throw(out)\n  .         }\n  .         inherit <- .subset2(.subset2(cnd, \"rlang\"), \"inherit\")\n  .         if (is_false(inherit)) {\n  .             return()\n  .         }\n  .         cnd <- .subset2(cnd, \"parent\")\n  .     }\n  . })(structure(list(message = \"Invalid Error: Conversion Error: CSV Error on Line: 178816\\nOriginal Line: china,china,4/1/02,8/22/00,,f1,,4/4/1012,university of cincinnati,cincinnati,ohio,45221,11.0701,computer science,,,,,9/1/00,8/31/03,msc,jacksonville,fl,32224,,cpt,4/28/03,8/31/03,,,,,,full time,,996,9585,,,3000,,terminated,master's,135546,143554,2004,2004\\nError when converting column \\\"VISA_EXPIRATION_DATE\\\". Could not convert string \\\"4/4/1012\\\" to 'DATE'\\n\\nColumn VISA_EXPIRATION_DATE is being converted as type DATE\\nThis type was auto-detected from the CSV file.\\nPossible solutions:\\n* Override the type for this column manually by setting the type explicitly, e.g., types={'VISA_EXPIRATION_DATE': 'VARCHAR'}\\n* Set the sample size to a larger value to enable the auto-detection to scan more values, e.g., sample_size=-1\\n* Use a COPY statement to automatically derive types from an existing table.\\n* Check whether the null string value is set correctly (e.g., nullstr = 'N/A')\\n\\n  file = ../data/cleaned/cleaned_2004_all.csv\\n  delimiter = , (Auto-Detected)\\n  quote = \\\" (Auto-Detected)\\n  escape = \\\" (Auto-Detected)\\n  new_line = \\\\n (Auto-Detected)\\n  header = true (Auto-Detected)\\n  skip_rows = 0 (Auto-Detected)\\n  comment = (empty) (Auto-Detected)\\n  strict_mode = true (Auto-Detected)\\n  date_format = %m/%d/%y (Auto-Detected)\\n  timestamp_format =  (Auto-Detected)\\n  null_padding = 0\\n  sample_size = 20480\\n  ignore_errors = false\\n  all_varchar = 0\\n\\n\\n\\033[34mℹ\\033[39m Context: rapi_execute\\n\\033[34mℹ\\033[39m Error type: INVALID\\n\\033[34mℹ\\033[39m Raw message: Conversion Error: CSV Error on Line: 178816\\nOriginal Line: china,china,4/1/02,8/22/00,,f1,,4/4/1012,university of cincinnati,cincinnati,ohio,45221,11.0701,computer science,,,,,9/1/00,8/31/03,msc,jacksonville,fl,32224,,cpt,4/28/03,8/31/03,,,,,,full time,,996,9585,,,3000,,terminated,master's,135546,143554,2004,2004\\nError when converting column \\\"VISA_EXPIRATION_DATE\\\". Could not convert string \\\"4/4/1012\\\" to 'DATE'\\n\\nColumn VISA_EXPIRATION_DATE is being converted as type DATE\\nThis type was auto-detected from the CSV file.\\nPossible solutions:\\n* Override the type for this column manually by setting the type explicitly, e.g., types={'VISA_EXPIRATION_DATE': 'VARCHAR'}\\n* Set the sample size to a larger value to enable the auto-detection to scan more values, e.g., sample_size=-1\\n* Use a COPY statement to automatically derive types from an existing table.\\n* Check whether the null string value is set correctly (e.g., nullstr = 'N/A')\\n\\n  file = ../data/cleaned/cleaned_2004_all.csv\\n  delimiter = , (Auto-Detected)\\n  quote = \\\" (Auto-Detected)\\n  escape = \\\" (Auto-Detected)\\n  new_line = \\\\n (Auto-Detected)\\n  header = true (Auto-Detected)\\n  skip_rows = 0 (Auto-Detected)\\n  comment = (empty) (Auto-Detected)\\n  strict_mode = true (Auto-Detected)\\n  date_format = %m/%d/%y (Auto-Detected)\\n  timestamp_format =  (Auto-Detected)\\n  null_padding = 0\\n  sample_size = 20480\\n  ignore_errors = false\\n  all_varchar = 0\\n\\n\", \n  .     trace = structure(list(call = list(IRkernel::main(), kernel$run(), \n  .         handle_shell(), executor$execute(msg), tryCatch(evaluate(request$content$code, \n  .             envir = .GlobalEnv, output_handler = oh, stop_on_error = 1L), \n  .             interrupt = function(cond) {\n  .                 log_debug(\"Interrupt during execution\")\n  .                 interrupted <<- TRUE\n  .             }, error = .self$handle_error), tryCatchList(expr, \n  .             classes, parentenv, handlers), tryCatchOne(tryCatchList(expr, \n  .             names[-nh], parentenv, handlers[-nh]), names[nh], \n  .             parentenv, handlers[[nh]]), doTryCatch(return(expr), \n  .             name, parentenv, handler), tryCatchList(expr, names[-nh], \n  .             parentenv, handlers[-nh]), tryCatchOne(expr, names, \n  .             parentenv, handlers[[1L]]), doTryCatch(return(expr), \n  .             name, parentenv, handler), evaluate(request$content$code, \n  .             envir = .GlobalEnv, output_handler = oh, stop_on_error = 1L), \n  .         withRestarts(with_handlers({\n  .             for (expr in tle$exprs) {\n  .                 ev <- withVisible(eval(expr, envir))\n  .                 watcher$capture_plot_and_output()\n  .                 watcher$print_value(ev$value, ev$visible, envir)\n  .             }\n  .             TRUE\n  .         }, handlers), eval_continue = function() TRUE, eval_stop = function() FALSE), \n  .         withRestartList(expr, restarts), withOneRestart(withRestartList(expr, \n  .             restarts[-nr]), restarts[[nr]]), doWithOneRestart(return(expr), \n  .             restart), withRestartList(expr, restarts[-nr]), withOneRestart(expr, \n  .             restarts[[1L]]), doWithOneRestart(return(expr), restart), \n  .         with_handlers({\n  .             for (expr in tle$exprs) {\n  .                 ev <- withVisible(eval(expr, envir))\n  .                 watcher$capture_plot_and_output()\n  .                 watcher$print_value(ev$value, ev$visible, envir)\n  .             }\n  .             TRUE\n  .         }, handlers), eval(call), eval(call), withCallingHandlers(code, \n  .             message = `<fn>`, warning = `<fn>`, error = `<fn>`), \n  .         withVisible(eval(expr, envir)), eval(expr, envir), eval(expr, \n  .             envir), dbExecute(con, query_sevis_id), dbExecute(con, \n  .             query_sevis_id), dbSendStatement(conn, statement, \n  .             ...), dbSendStatement(conn, statement, ...), dbSendQuery(conn, \n  .             statement, ...), dbSendQuery(conn, statement, ...), \n  .         .local(conn, statement, ...), duckdb_result(connection = conn, \n  .             stmt_lst = stmt_lst, arrow = arrow), duckdb_execute(res), \n  .         rethrow_rapi_execute(res@stmt_lst$ref, duckdb_convert_opts_impl(res@connection@convert_opts, \n  .             arrow = res@arrow)), rlang::try_fetch(rapi_execute(stmt, \n  .             convert_opts), error = function(e) {\n  .             rethrow_error_from_rapi(e, call)\n  .         }), tryCatch(withCallingHandlers(expr, condition = function(cnd) {\n  .             {\n  .                 .__handler_frame__. <- TRUE\n  .                 .__setup_frame__. <- frame\n  .                 if (inherits(cnd, \"message\")) {\n  .                   except <- c(\"warning\", \"error\")\n  .                 }\n  .                 else if (inherits(cnd, \"warning\")) {\n  .                   except <- \"error\"\n  .                 }\n  .                 else {\n  .                   except <- \"\"\n  .                 }\n  .             }\n  .             while (!is_null(cnd)) {\n  .                 if (inherits(cnd, \"error\")) {\n  .                   out <- handlers[[1L]](cnd)\n  .                   if (!inherits(out, \"rlang_zap\")) \n  .                     throw(out)\n  .                 }\n  .                 inherit <- .subset2(.subset2(cnd, \"rlang\"), \"inherit\")\n  .                 if (is_false(inherit)) {\n  .                   return()\n  .                 }\n  .                 cnd <- .subset2(cnd, \"parent\")\n  .             }\n  .         }), stackOverflowError = handlers[[1L]]), tryCatchList(expr, \n  .             classes, parentenv, handlers), tryCatchOne(expr, \n  .             names, parentenv, handlers[[1L]]), doTryCatch(return(expr), \n  .             name, parentenv, handler), withCallingHandlers(expr, \n  .             condition = function(cnd) {\n  .                 {\n  .                   .__handler_frame__. <- TRUE\n  .                   .__setup_frame__. <- frame\n  .                   if (inherits(cnd, \"message\")) {\n  .                     except <- c(\"warning\", \"error\")\n  .                   }\n  .                   else if (inherits(cnd, \"warning\")) {\n  .                     except <- \"error\"\n  .                   }\n  .                   else {\n  .                     except <- \"\"\n  .                   }\n  .                 }\n  .                 while (!is_null(cnd)) {\n  .                   if (inherits(cnd, \"error\")) {\n  .                     out <- handlers[[1L]](cnd)\n  .                     if (!inherits(out, \"rlang_zap\")) \n  .                       throw(out)\n  .                   }\n  .                   inherit <- .subset2(.subset2(cnd, \"rlang\"), \n  .                     \"inherit\")\n  .                   if (is_false(inherit)) {\n  .                     return()\n  .                   }\n  .                   cnd <- .subset2(cnd, \"parent\")\n  .                 }\n  .             }), rapi_execute(stmt, convert_opts), `<fn>`(\"rapi_execute\", \n  .             \"Invalid Error: Conversion Error: CSV Error on Line: 178816\\nOriginal Line: china,china,4/1/02,8/22/00,,f1,,4/4/1012,university of cincinnati,cincinnati,ohio,45221,11.0701,computer science,,,,,9/1/00,8/31/03,msc,jacksonville,fl,32224,,cpt,4/28/03,8/31/03,,,,,,full time,,996,9585,,,3000,,terminated,master's,135546,143554,2004,2004\\nError when converting column \\\"VISA_EXPIRATION_DATE\\\". Could not convert string \\\"4/4/1012\\\" to 'DATE'\\n\\nColumn VISA_EXPIRATION_DATE is being converted as type DATE\\nThis type was auto-detected from the CSV file.\\nPossible solutions:\\n* Override the type for this column manually by setting the type explicitly, e.g., types={'VISA_EXPIRATION_DATE': 'VARCHAR'}\\n* Set the sample size to a larger value to enable the auto-detection to scan more values, e.g., sample_size=-1\\n* Use a COPY statement to automatically derive types from an existing table.\\n* Check whether the null string value is set correctly (e.g., nullstr = 'N/A')\\n\\n  file = ../data/cleaned/cleaned_2004_all.csv\\n  delimiter = , (Auto-Detected)\\n  quote = \\\" (Auto-Detected)\\n  escape = \\\" (Auto-Detected)\\n  new_line = \\\\n (Auto-Detected)\\n  header = true (Auto-Detected)\\n  skip_rows = 0 (Auto-Detected)\\n  comment = (empty) (Auto-Detected)\\n  strict_mode = true (Auto-Detected)\\n  date_format = %m/%d/%y (Auto-Detected)\\n  timestamp_format =  (Auto-Detected)\\n  null_padding = 0\\n  sample_size = 20480\\n  ignore_errors = false\\n  all_varchar = 0\\n\\n\", \n  .             \"INVALID\", \"Conversion Error: CSV Error on Line: 178816\\nOriginal Line: china,china,4/1/02,8/22/00,,f1,,4/4/1012,university of cincinnati,cincinnati,ohio,45221,11.0701,computer science,,,,,9/1/00,8/31/03,msc,jacksonville,fl,32224,,cpt,4/28/03,8/31/03,,,,,,full time,,996,9585,,,3000,,terminated,master's,135546,143554,2004,2004\\nError when converting column \\\"VISA_EXPIRATION_DATE\\\". Could not convert string \\\"4/4/1012\\\" to 'DATE'\\n\\nColumn VISA_EXPIRATION_DATE is being converted as type DATE\\nThis type was auto-detected from the CSV file.\\nPossible solutions:\\n* Override the type for this column manually by setting the type explicitly, e.g., types={'VISA_EXPIRATION_DATE': 'VARCHAR'}\\n* Set the sample size to a larger value to enable the auto-detection to scan more values, e.g., sample_size=-1\\n* Use a COPY statement to automatically derive types from an existing table.\\n* Check whether the null string value is set correctly (e.g., nullstr = 'N/A')\\n\\n  file = ../data/cleaned/cleaned_2004_all.csv\\n  delimiter = , (Auto-Detected)\\n  quote = \\\" (Auto-Detected)\\n  escape = \\\" (Auto-Detected)\\n  new_line = \\\\n (Auto-Detected)\\n  header = true (Auto-Detected)\\n  skip_rows = 0 (Auto-Detected)\\n  comment = (empty) (Auto-Detected)\\n  strict_mode = true (Auto-Detected)\\n  date_format = %m/%d/%y (Auto-Detected)\\n  timestamp_format =  (Auto-Detected)\\n  null_padding = 0\\n  sample_size = 20480\\n  ignore_errors = false\\n  all_varchar = 0\\n\\n\", \n  .             `<list>`), rlang::abort(error_parts, class = \"duckdb_error\", \n  .             !!!fields)), parent = c(0L, 1L, 2L, 3L, 4L, 5L, 6L, \n  .     7L, 6L, 9L, 10L, 4L, 12L, 13L, 14L, 15L, 14L, 17L, 18L, 12L, \n  .     20L, 21L, 20L, 12L, 12L, 25L, 0L, 0L, 28L, 28L, 30L, 30L, \n  .     32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 37L, 36L, 0L, \n  .     44L), visible = c(TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, \n  .     TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, \n  .     TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, \n  .     TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, \n  .     TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE), namespace = c(\"IRkernel\", \n  .     NA, \"IRkernel\", NA, \"base\", \"base\", \"base\", \"base\", \"base\", \n  .     \"base\", \"base\", \"evaluate\", \"base\", \"base\", \"base\", \"base\", \n  .     \"base\", \"base\", \"base\", \"evaluate\", \"base\", \"base\", \"base\", \n  .     \"base\", \"base\", \"base\", \"DBI\", \"DBI\", \"DBI\", \"DBI\", \"DBI\", \n  .     \"duckdb\", \"duckdb\", \"duckdb\", \"duckdb\", \"duckdb\", \"rlang\", \n  .     \"base\", \"base\", \"base\", \"base\", \"base\", \"duckdb\", \"duckdb\", \n  .     \"rlang\"), scope = c(\"::\", NA, \"local\", NA, \"::\", \"local\", \n  .     \"local\", \"local\", \"local\", \"local\", \"local\", \"::\", \"::\", \n  .     \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \":::\", \n  .     \"::\", \"::\", \"::\", \"::\", \"::\", \"::\", \"::\", \"::\", \"::\", \"::\", \n  .     \"::\", \"::\", \"local\", \":::\", \":::\", \":::\", \"::\", \"::\", \"local\", \n  .     \"local\", \"local\", \"::\", \":::\", \"local\", \"::\"), error_frame = c(FALSE, \n  .     FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, \n  .     FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, \n  .     FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, \n  .     FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, \n  .     FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE)), row.names = c(NA, \n  .     -45L), version = 2L, class = c(\"rlang_trace\", \"rlib_trace\", \n  .     \"tbl\", \"data.frame\")), parent = NULL, context = \"rapi_execute\", \n  .     error_type = \"INVALID\", raw_message = \"Conversion Error: CSV Error on Line: 178816\\nOriginal Line: china,china,4/1/02,8/22/00,,f1,,4/4/1012,university of cincinnati,cincinnati,ohio,45221,11.0701,computer science,,,,,9/1/00,8/31/03,msc,jacksonville,fl,32224,,cpt,4/28/03,8/31/03,,,,,,full time,,996,9585,,,3000,,terminated,master's,135546,143554,2004,2004\\nError when converting column \\\"VISA_EXPIRATION_DATE\\\". Could not convert string \\\"4/4/1012\\\" to 'DATE'\\n\\nColumn VISA_EXPIRATION_DATE is being converted as type DATE\\nThis type was auto-detected from the CSV file.\\nPossible solutions:\\n* Override the type for this column manually by setting the type explicitly, e.g., types={'VISA_EXPIRATION_DATE': 'VARCHAR'}\\n* Set the sample size to a larger value to enable the auto-detection to scan more values, e.g., sample_size=-1\\n* Use a COPY statement to automatically derive types from an existing table.\\n* Check whether the null string value is set correctly (e.g., nullstr = 'N/A')\\n\\n  file = ../data/cleaned/cleaned_2004_all.csv\\n  delimiter = , (Auto-Detected)\\n  quote = \\\" (Auto-Detected)\\n  escape = \\\" (Auto-Detected)\\n  new_line = \\\\n (Auto-Detected)\\n  header = true (Auto-Detected)\\n  skip_rows = 0 (Auto-Detected)\\n  comment = (empty) (Auto-Detected)\\n  strict_mode = true (Auto-Detected)\\n  date_format = %m/%d/%y (Auto-Detected)\\n  timestamp_format =  (Auto-Detected)\\n  null_padding = 0\\n  sample_size = 20480\\n  ignore_errors = false\\n  all_varchar = 0\\n\\n\", \n  .     extra_info = list(), rlang = list(inherit = TRUE), call = (function (context, \n  .         message, error_type = NULL, raw_message = NULL, extra_info = NULL) \n  .     {\n  .         fields <- list()\n  .         fields$context <- context\n  .         fields$error_type <- error_type\n  .         fields$raw_message <- raw_message\n  .         fields$extra_info <- extra_info\n  .         error_parts <- c(message, i = paste0(\"Context: \", context))\n  .         if (!is.null(error_type)) {\n  .             error_parts <- c(error_parts, i = paste0(\"Error type: \", \n  .                 error_type))\n  .         }\n  .         if (!is.null(raw_message) && raw_message != message) {\n  .             error_parts <- c(error_parts, i = paste0(\"Raw message: \", \n  .                 raw_message))\n  .         }\n  .         if (length(extra_info) > 0) {\n  .             info_text <- paste0(names(extra_info), \": \", extra_info)\n  .             names(info_text) <- rep_len(\"i\", length(info_text))\n  .             error_parts <- c(error_parts, info_text)\n  .         }\n  .         rlang::abort(error_parts, class = \"duckdb_error\", !!!fields)\n  .     })(\"rapi_execute\", \"Invalid Error: Conversion Error: CSV Error on Line: 178816\\nOriginal Line: china,china,4/1/02,8/22/00,,f1,,4/4/1012,university of cincinnati,cincinnati,ohio,45221,11.0701,computer science,,,,,9/1/00,8/31/03,msc,jacksonville,fl,32224,,cpt,4/28/03,8/31/03,,,,,,full time,,996,9585,,,3000,,terminated,master's,135546,143554,2004,2004\\nError when converting column \\\"VISA_EXPIRATION_DATE\\\". Could not convert string \\\"4/4/1012\\\" to 'DATE'\\n\\nColumn VISA_EXPIRATION_DATE is being converted as type DATE\\nThis type was auto-detected from the CSV file.\\nPossible solutions:\\n* Override the type for this column manually by setting the type explicitly, e.g., types={'VISA_EXPIRATION_DATE': 'VARCHAR'}\\n* Set the sample size to a larger value to enable the auto-detection to scan more values, e.g., sample_size=-1\\n* Use a COPY statement to automatically derive types from an existing table.\\n* Check whether the null string value is set correctly (e.g., nullstr = 'N/A')\\n\\n  file = ../data/cleaned/cleaned_2004_all.csv\\n  delimiter = , (Auto-Detected)\\n  quote = \\\" (Auto-Detected)\\n  escape = \\\" (Auto-Detected)\\n  new_line = \\\\n (Auto-Detected)\\n  header = true (Auto-Detected)\\n  skip_rows = 0 (Auto-Detected)\\n  comment = (empty) (Auto-Detected)\\n  strict_mode = true (Auto-Detected)\\n  date_format = %m/%d/%y (Auto-Detected)\\n  timestamp_format =  (Auto-Detected)\\n  null_padding = 0\\n  sample_size = 20480\\n  ignore_errors = false\\n  all_varchar = 0\\n\\n\", \n  .         \"INVALID\", \"Conversion Error: CSV Error on Line: 178816\\nOriginal Line: china,china,4/1/02,8/22/00,,f1,,4/4/1012,university of cincinnati,cincinnati,ohio,45221,11.0701,computer science,,,,,9/1/00,8/31/03,msc,jacksonville,fl,32224,,cpt,4/28/03,8/31/03,,,,,,full time,,996,9585,,,3000,,terminated,master's,135546,143554,2004,2004\\nError when converting column \\\"VISA_EXPIRATION_DATE\\\". Could not convert string \\\"4/4/1012\\\" to 'DATE'\\n\\nColumn VISA_EXPIRATION_DATE is being converted as type DATE\\nThis type was auto-detected from the CSV file.\\nPossible solutions:\\n* Override the type for this column manually by setting the type explicitly, e.g., types={'VISA_EXPIRATION_DATE': 'VARCHAR'}\\n* Set the sample size to a larger value to enable the auto-detection to scan more values, e.g., sample_size=-1\\n* Use a COPY statement to automatically derive types from an existing table.\\n* Check whether the null string value is set correctly (e.g., nullstr = 'N/A')\\n\\n  file = ../data/cleaned/cleaned_2004_all.csv\\n  delimiter = , (Auto-Detected)\\n  quote = \\\" (Auto-Detected)\\n  escape = \\\" (Auto-Detected)\\n  new_line = \\\\n (Auto-Detected)\\n  header = true (Auto-Detected)\\n  skip_rows = 0 (Auto-Detected)\\n  comment = (empty) (Auto-Detected)\\n  strict_mode = true (Auto-Detected)\\n  date_format = %m/%d/%y (Auto-Detected)\\n  timestamp_format =  (Auto-Detected)\\n  null_padding = 0\\n  sample_size = 20480\\n  ignore_errors = false\\n  all_varchar = 0\\n\\n\", \n  .         list())), class = c(\"duckdb_error\", \"rlang_error\", \"error\", \n  . \"condition\")))",
      "22. handlers[[1L]](cnd)",
      "23. rethrow_error_from_rapi(e, call)   # at line 511 of file /private/var/folders/3r/fm67pndj58l3r5mfj16fw8km0000gn/T/Rtmp8zMAme/renv-package-new-16a3a7de3bc46/duckdb/R/rethrow-gen.R",
      "24. rlang::abort(msg, call = call)   # at line 17 of file /private/var/folders/3r/fm67pndj58l3r5mfj16fw8km0000gn/T/Rtmp8zMAme/renv-package-new-16a3a7de3bc46/duckdb/R/rethrow.R",
      "25. signal_abort(cnd, .file)",
      "26. signalCondition(cnd)"
     ]
    }
   ],
   "source": [
    "cat(\"\\n=== Step 1: Creating SEVIS_ID ===\")\n",
    "cat(\"\\nReading raw data and creating SEVIS_ID column...\\n\")\n",
    "\n",
    "query_sevis_id <- sprintf(\"\n",
    "CREATE OR REPLACE TEMP TABLE base_data AS\n",
    "SELECT \n",
    "  *,\n",
    "  CONCAT(CAST(Year AS VARCHAR), Individual_Key) AS SEVIS_ID\n",
    "FROM read_csv_auto('%s', union_by_name=true)\n",
    "\", RAW_DATA_PATH)\n",
    "\n",
    "dbExecute(con, query_sevis_id)\n",
    "\n",
    "# Get row count\n",
    "row_count <- dbGetQuery(con, \"SELECT COUNT(*) as count FROM base_data\")$count\n",
    "cat(sprintf(\"✓ Base data loaded: %s rows\\n\", format(row_count, big.mark=\",\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Add IS_STEM Column\n",
    "\n",
    "Marks records as STEM based on DHS STEM CIP code list (considers any major or minor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"\\n=== Step 2: Adding IS_STEM column ===\")\n",
    "cat(\"\\nJoining to DHS STEM CIP code list...\\n\")\n",
    "\n",
    "query_is_stem <- sprintf(\"\n",
    "CREATE OR REPLACE TEMP TABLE with_stem AS\n",
    "SELECT \n",
    "  b.*,\n",
    "  CASE\n",
    "    -- If all CIP fields are missing/blank, keep unknown as NULL\n",
    "    WHEN NULLIF(TRIM(b.Major_1_CIP_Code), '') IS NULL \n",
    "     AND NULLIF(TRIM(b.Major_2_CIP_Code), '') IS NULL \n",
    "     AND NULLIF(TRIM(b.Minor_CIP_Code), '') IS NULL\n",
    "    THEN NULL\n",
    "    -- Otherwise TRUE if any CIP matches the DHS STEM list\n",
    "    ELSE EXISTS (\n",
    "      SELECT 1\n",
    "      FROM (\n",
    "        SELECT UNNEST([b.Major_1_CIP_Code, b.Major_2_CIP_Code, b.Minor_CIP_Code]) AS cip\n",
    "      ) cips\n",
    "      JOIN read_csv_auto('%s') AS stem_list\n",
    "        ON LOWER(REPLACE(TRIM(stem_list.\\\"2020_cip_code\\\"), ' ', '')) \n",
    "         = LOWER(REPLACE(TRIM(cips.cip), ' ', ''))\n",
    "    )\n",
    "  END AS IS_STEM\n",
    "FROM base_data b\n",
    "\", DHS_STEM_LIST)\n",
    "\n",
    "dbExecute(con, query_is_stem)\n",
    "\n",
    "# Get STEM count\n",
    "stem_stats <- dbGetQuery(con, \"\n",
    "  SELECT \n",
    "    COUNT(*) as total,\n",
    "    SUM(CASE WHEN IS_STEM = TRUE THEN 1 ELSE 0 END) as stem_count,\n",
    "    SUM(CASE WHEN IS_STEM IS NULL THEN 1 ELSE 0 END) as unknown_count\n",
    "  FROM with_stem\n",
    "\")\n",
    "\n",
    "cat(sprintf(\"✓ STEM classification complete:\\n\"))\n",
    "cat(sprintf(\"  - STEM: %s (%.1f%%)\\n\", \n",
    "            format(stem_stats$stem_count, big.mark=\",\"),\n",
    "            100 * stem_stats$stem_count / stem_stats$total))\n",
    "cat(sprintf(\"  - Non-STEM: %s (%.1f%%)\\n\", \n",
    "            format(stem_stats$total - stem_stats$stem_count - stem_stats$unknown_count, big.mark=\",\"),\n",
    "            100 * (stem_stats$total - stem_stats$stem_count - stem_stats$unknown_count) / stem_stats$total))\n",
    "cat(sprintf(\"  - Unknown: %s (%.1f%%)\\n\", \n",
    "            format(stem_stats$unknown_count, big.mark=\",\"),\n",
    "            100 * stem_stats$unknown_count / stem_stats$total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Add NSF_SUBJ_FIELD_BROAD Column\n",
    "\n",
    "Maps CIP codes to NSF broad subject fields (based on first major only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"\\n=== Step 3: Adding NSF_SUBJ_FIELD_BROAD column ===\")\n",
    "cat(\"\\nMapping CIP codes to NSF fields...\\n\")\n",
    "\n",
    "# Helper function to normalize CIP codes (MM.mmmm format)\n",
    "query_nsf <- sprintf(\"\n",
    "CREATE OR REPLACE TEMP TABLE with_nsf AS\n",
    "SELECT \n",
    "  w.*,\n",
    "  m.NSF_BROAD_FIELD AS NSF_SUBJ_FIELD_BROAD\n",
    "FROM with_stem w\n",
    "LEFT JOIN (\n",
    "  SELECT DISTINCT\n",
    "    -- Normalize CIP code to MM.mmmm format\n",
    "    CONCAT(\n",
    "      LPAD(REGEXP_EXTRACT(TRIM(CIPCODE_ORIGINAL), '(\\\\d+)', 1), 2, '0'),\n",
    "      '.',\n",
    "      RPAD(COALESCE(REGEXP_EXTRACT(TRIM(CIPCODE_ORIGINAL), '\\\\d+\\\\.(\\\\d+)$', 1), ''), 4, '0')\n",
    "    ) AS cip_normalized,\n",
    "    NSF_BROAD_FIELD\n",
    "  FROM read_csv_auto('%s')\n",
    ") m\n",
    "  ON CONCAT(\n",
    "       LPAD(REGEXP_EXTRACT(TRIM(CAST(w.Major_1_CIP_Code AS VARCHAR)), '(\\\\d+)', 1), 2, '0'),\n",
    "       '.',\n",
    "       RPAD(COALESCE(REGEXP_EXTRACT(TRIM(CAST(w.Major_1_CIP_Code AS VARCHAR)), '\\\\d+\\\\.(\\\\d+)$', 1), ''), 4, '0')\n",
    "     ) = m.cip_normalized\n",
    "\", CIP_TO_NSF_MAPPING)\n",
    "\n",
    "dbExecute(con, query_nsf)\n",
    "\n",
    "# Get NSF field stats\n",
    "nsf_stats <- dbGetQuery(con, \"\n",
    "  SELECT \n",
    "    COUNT(*) as total,\n",
    "    COUNT(NSF_SUBJ_FIELD_BROAD) as mapped_count\n",
    "  FROM with_nsf\n",
    "\")\n",
    "\n",
    "cat(sprintf(\"✓ NSF field mapping complete: %s/%s records mapped (%.1f%%)\\n\",\n",
    "            format(nsf_stats$mapped_count, big.mark=\",\"),\n",
    "            format(nsf_stats$total, big.mark=\",\"),\n",
    "            100 * nsf_stats$mapped_count / nsf_stats$total))\n",
    "\n",
    "# Show top NSF fields\n",
    "top_fields <- dbGetQuery(con, \"\n",
    "  SELECT NSF_SUBJ_FIELD_BROAD, COUNT(*) as count\n",
    "  FROM with_nsf\n",
    "  WHERE NSF_SUBJ_FIELD_BROAD IS NOT NULL\n",
    "  GROUP BY NSF_SUBJ_FIELD_BROAD\n",
    "  ORDER BY count DESC\n",
    "  LIMIT 5\n",
    "\")\n",
    "\n",
    "cat(\"\\nTop 5 NSF fields:\\n\")\n",
    "for (i in 1:nrow(top_fields)) {\n",
    "  cat(sprintf(\"  %d. %s: %s\\n\", i, top_fields$NSF_SUBJ_FIELD_BROAD[i], \n",
    "              format(top_fields$count[i], big.mark=\",\")))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Add Geographic Columns (LMA and County)\n",
    "\n",
    "Maps ZIP codes to Labor Market Areas (LMAs) and counties based on Program End Date quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"\\n=== Step 4: Adding geographic columns (CAMPUS_LMA, EMPLOYER_LMA, CAMPUS_COUNTY, EMPLOYER_COUNTY) ===\")\n",
    "cat(\"\\nThis may take several minutes...\\n\")\n",
    "\n",
    "# First, create a slim ZIP→LMA lookup table\n",
    "cat(\"\\nStep 4a: Creating ZIP→LMA lookup...\\n\")\n",
    "query_lma_lookup <- sprintf(\"\n",
    "CREATE OR REPLACE TEMP TABLE zip_lma_slim AS\n",
    "WITH cleaned AS (\n",
    "  SELECT\n",
    "    CAST(YEAR AS INTEGER) AS year,\n",
    "    CAST(QUARTER AS INTEGER) AS quarter,\n",
    "    SUBSTR(REGEXP_REPLACE(TRIM(zip5), '[^0-9]', ''), 1, 5) AS zip5_norm,\n",
    "    lma_name\n",
    "  FROM read_csv_auto('%s')\n",
    ")\n",
    "SELECT year, quarter, zip5_norm, lma_name\n",
    "FROM cleaned\n",
    "WHERE year IS NOT NULL\n",
    "  AND quarter BETWEEN 1 AND 4\n",
    "  AND LENGTH(zip5_norm) = 5\n",
    "  AND zip5_norm <> '00000'\n",
    "QUALIFY ROW_NUMBER() OVER (\n",
    "  PARTITION BY year, quarter, zip5_norm\n",
    "  ORDER BY lma_name\n",
    ") = 1\n",
    "\", ZIP_LMA_MAPPING)\n",
    "\n",
    "dbExecute(con, query_lma_lookup)\n",
    "lma_count <- dbGetQuery(con, \"SELECT COUNT(*) as count FROM zip_lma_slim\")$count\n",
    "cat(sprintf(\"✓ ZIP→LMA lookup created: %s mappings\\n\", format(lma_count, big.mark=\",\")))\n",
    "\n",
    "# Create ZIP→County lookup table\n",
    "cat(\"\\nStep 4b: Creating ZIP→County lookup...\\n\")\n",
    "query_county_lookup <- sprintf(\"\n",
    "CREATE OR REPLACE TEMP TABLE zip_county_slim AS\n",
    "WITH cw AS (\n",
    "  SELECT\n",
    "    CAST(YEAR AS INTEGER) AS year,\n",
    "    CAST(QUARTER AS INTEGER) AS quarter,\n",
    "    SUBSTR(REGEXP_REPLACE(TRIM(ZIP), '[^0-9]', ''), 1, 5) AS zip5_norm,\n",
    "    COUNTY AS county5\n",
    "  FROM read_csv_auto('%s')\n",
    "),\n",
    "wp AS (\n",
    "  SELECT\n",
    "    LPAD(CAST(CAST(TRIM(CAST(County_LAUS_areacode AS VARCHAR)) AS INTEGER) AS VARCHAR), 5, '0') AS county5,\n",
    "    County_Name_State_Abbreviation\n",
    "  FROM read_csv_auto('%s')\n",
    ")\n",
    "SELECT\n",
    "  cw.year,\n",
    "  cw.quarter,\n",
    "  cw.zip5_norm,\n",
    "  wp.County_Name_State_Abbreviation\n",
    "FROM cw\n",
    "JOIN wp USING (county5)\n",
    "WHERE cw.year IS NOT NULL\n",
    "  AND cw.quarter BETWEEN 1 AND 4\n",
    "  AND LENGTH(cw.zip5_norm) = 5\n",
    "  AND cw.zip5_norm <> '00000'\n",
    "QUALIFY ROW_NUMBER() OVER (\n",
    "  PARTITION BY year, quarter, zip5_norm\n",
    "  ORDER BY County_Name_State_Abbreviation\n",
    ") = 1\n",
    "\", ZIP_COUNTY_CROSSWALK, WORKING_POP_BY_COUNTY)\n",
    "\n",
    "dbExecute(con, query_county_lookup)\n",
    "county_count <- dbGetQuery(con, \"SELECT COUNT(*) as count FROM zip_county_slim\")$count\n",
    "cat(sprintf(\"✓ ZIP→County lookup created: %s mappings\\n\", format(county_count, big.mark=\",\")))\n",
    "\n",
    "# Now join to add all 4 geographic columns\n",
    "cat(\"\\nStep 4c: Joining geographic data to main dataset...\\n\")\n",
    "query_geo <- \"\n",
    "CREATE OR REPLACE TEMP TABLE with_geo AS\n",
    "SELECT \n",
    "  n.*,\n",
    "  lma_campus.lma_name AS CAMPUS_LMA,\n",
    "  lma_employer.lma_name AS EMPLOYER_LMA,\n",
    "  county_campus.County_Name_State_Abbreviation AS CAMPUS_COUNTY,\n",
    "  county_employer.County_Name_State_Abbreviation AS EMPLOYER_COUNTY\n",
    "FROM with_nsf n\n",
    "LEFT JOIN zip_lma_slim lma_campus\n",
    "  ON EXTRACT(YEAR FROM TRY_CAST(n.Program_End_Date AS DATE)) = lma_campus.year\n",
    " AND EXTRACT(QUARTER FROM TRY_CAST(n.Program_End_Date AS DATE)) = lma_campus.quarter\n",
    " AND n.Campus_Zip_Code = lma_campus.zip5_norm\n",
    "LEFT JOIN zip_lma_slim lma_employer\n",
    "  ON EXTRACT(YEAR FROM TRY_CAST(n.Program_End_Date AS DATE)) = lma_employer.year\n",
    " AND EXTRACT(QUARTER FROM TRY_CAST(n.Program_End_Date AS DATE)) = lma_employer.quarter\n",
    " AND n.Employer_Zip_Code = lma_employer.zip5_norm\n",
    "LEFT JOIN zip_county_slim county_campus\n",
    "  ON EXTRACT(YEAR FROM TRY_CAST(n.Program_End_Date AS DATE)) = county_campus.year\n",
    " AND EXTRACT(QUARTER FROM TRY_CAST(n.Program_End_Date AS DATE)) = county_campus.quarter\n",
    " AND n.Campus_Zip_Code = county_campus.zip5_norm\n",
    "LEFT JOIN zip_county_slim county_employer\n",
    "  ON EXTRACT(YEAR FROM TRY_CAST(n.Program_End_Date AS DATE)) = county_employer.year\n",
    " AND EXTRACT(QUARTER FROM TRY_CAST(n.Program_End_Date AS DATE)) = county_employer.quarter\n",
    " AND n.Employer_Zip_Code = county_employer.zip5_norm\n",
    "\"\n",
    "\n",
    "dbExecute(con, query_geo)\n",
    "\n",
    "# Get match rates\n",
    "geo_stats <- dbGetQuery(con, \"\n",
    "  SELECT \n",
    "    COUNT(*) as total,\n",
    "    COUNT(CAMPUS_LMA) as campus_lma_count,\n",
    "    COUNT(EMPLOYER_LMA) as employer_lma_count,\n",
    "    COUNT(CAMPUS_COUNTY) as campus_county_count,\n",
    "    COUNT(EMPLOYER_COUNTY) as employer_county_count\n",
    "  FROM with_geo\n",
    "\")\n",
    "\n",
    "cat(\"\\n✓ Geographic columns added:\\n\")\n",
    "cat(sprintf(\"  - CAMPUS_LMA: %s/%s (%.1f%%)\\n\",\n",
    "            format(geo_stats$campus_lma_count, big.mark=\",\"),\n",
    "            format(geo_stats$total, big.mark=\",\"),\n",
    "            100 * geo_stats$campus_lma_count / geo_stats$total))\n",
    "cat(sprintf(\"  - EMPLOYER_LMA: %s/%s (%.1f%%)\\n\",\n",
    "            format(geo_stats$employer_lma_count, big.mark=\",\"),\n",
    "            format(geo_stats$total, big.mark=\",\"),\n",
    "            100 * geo_stats$employer_lma_count / geo_stats$total))\n",
    "cat(sprintf(\"  - CAMPUS_COUNTY: %s/%s (%.1f%%)\\n\",\n",
    "            format(geo_stats$campus_county_count, big.mark=\",\"),\n",
    "            format(geo_stats$total, big.mark=\",\"),\n",
    "            100 * geo_stats$campus_county_count / geo_stats$total))\n",
    "cat(sprintf(\"  - EMPLOYER_COUNTY: %s/%s (%.1f%%)\\n\",\n",
    "            format(geo_stats$employer_county_count, big.mark=\",\"),\n",
    "            format(geo_stats$total, big.mark=\",\"),\n",
    "            100 * geo_stats$employer_county_count / geo_stats$total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Add Working Population Columns\n",
    "\n",
    "Adds working population data for employer LMA and state (for context/normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"\\n=== Step 5: Adding working population columns ===\")\n",
    "cat(\"\\nUnpivoting working population data...\\n\")\n",
    "\n",
    "# Create unpivoted working population lookup\n",
    "query_workpop <- sprintf(\"\n",
    "CREATE OR REPLACE TEMP TABLE workpop_long AS\n",
    "SELECT\n",
    "  County_Name_State_Abbreviation,\n",
    "  state_name,\n",
    "  CAST(year_col AS INTEGER) AS year,\n",
    "  CASE\n",
    "    WHEN LOWER(TRIM(pop_value)) IN ('missing data', '') THEN NULL\n",
    "    ELSE CAST(REPLACE(TRIM(pop_value), ',', '') AS INTEGER)\n",
    "  END AS working_pop\n",
    "FROM (\n",
    "  SELECT\n",
    "    County_Name_State_Abbreviation,\n",
    "    state_name,\n",
    "    UNNEST([\n",
    "      '2004','2005','2006','2007','2008','2009','2010','2011','2012','2013',\n",
    "      '2014','2015','2016','2017','2018','2019','2020','2021','2022','2023','2024'\n",
    "    ]) AS year_col,\n",
    "    UNNEST([\n",
    "      LMA_WORKING_POP_2004, LMA_WORKING_POP_2005, LMA_WORKING_POP_2006, LMA_WORKING_POP_2007,\n",
    "      LMA_WORKING_POP_2008, LMA_WORKING_POP_2009, LMA_WORKING_POP_2010, LMA_WORKING_POP_2011,\n",
    "      LMA_WORKING_POP_2012, LMA_WORKING_POP_2013, LMA_WORKING_POP_2014, LMA_WORKING_POP_2015,\n",
    "      LMA_WORKING_POP_2016, LMA_WORKING_POP_2017, LMA_WORKING_POP_2018, LMA_WORKING_POP_2019,\n",
    "      LMA_WORKING_POP_2020, LMA_WORKING_POP_2021, LMA_WORKING_POP_2022, LMA_WORKING_POP_2023,\n",
    "      LMA_WORKING_POP_2024\n",
    "    ]) AS pop_value\n",
    "  FROM read_csv_auto('%s')\n",
    ")\n",
    "WHERE year BETWEEN 2004 AND 2024\n",
    "\", WORKING_POP_BY_COUNTY)\n",
    "\n",
    "dbExecute(con, query_workpop)\n",
    "\n",
    "# Aggregate to state level\n",
    "cat(\"Creating state-level aggregates...\\n\")\n",
    "dbExecute(con, \"\n",
    "CREATE OR REPLACE TEMP TABLE workpop_state AS\n",
    "SELECT\n",
    "  state_name,\n",
    "  year,\n",
    "  SUM(working_pop) AS state_working_pop\n",
    "FROM workpop_long\n",
    "WHERE state_name IS NOT NULL\n",
    "GROUP BY state_name, year\n",
    "\")\n",
    "\n",
    "# Join to main dataset\n",
    "cat(\"Joining working population data...\\n\")\n",
    "query_final <- \"\n",
    "CREATE OR REPLACE TEMP TABLE enriched_master AS\n",
    "SELECT \n",
    "  g.*,\n",
    "  wp_lma.working_pop AS EMPLOYER_LMA_WORKPOP_YR,\n",
    "  wp_state.state_working_pop AS EMPLOYER_STATE_WORKPOP_YR\n",
    "FROM with_geo g\n",
    "LEFT JOIN workpop_long wp_lma\n",
    "  ON g.EMPLOYER_COUNTY = wp_lma.County_Name_State_Abbreviation\n",
    " AND EXTRACT(YEAR FROM TRY_CAST(g.Authorization_Start_Date AS DATE)) = wp_lma.year\n",
    "LEFT JOIN workpop_state wp_state\n",
    "  ON g.Employer_State = wp_state.state_name\n",
    " AND EXTRACT(YEAR FROM TRY_CAST(g.Authorization_Start_Date AS DATE)) = wp_state.year\n",
    "\"\n",
    "\n",
    "dbExecute(con, query_final)\n",
    "\n",
    "workpop_stats <- dbGetQuery(con, \"\n",
    "  SELECT \n",
    "    COUNT(*) as total,\n",
    "    COUNT(EMPLOYER_LMA_WORKPOP_YR) as lma_pop_count,\n",
    "    COUNT(EMPLOYER_STATE_WORKPOP_YR) as state_pop_count\n",
    "  FROM enriched_master\n",
    "\")\n",
    "\n",
    "cat(\"\\n✓ Working population columns added:\\n\")\n",
    "cat(sprintf(\"  - EMPLOYER_LMA_WORKPOP_YR: %s/%s (%.1f%%)\\n\",\n",
    "            format(workpop_stats$lma_pop_count, big.mark=\",\"),\n",
    "            format(workpop_stats$total, big.mark=\",\"),\n",
    "            100 * workpop_stats$lma_pop_count / workpop_stats$total))\n",
    "cat(sprintf(\"  - EMPLOYER_STATE_WORKPOP_YR: %s/%s (%.1f%%)\\n\",\n",
    "            format(workpop_stats$state_pop_count, big.mark=\",\"),\n",
    "            format(workpop_stats$total, big.mark=\",\"),\n",
    "            100 * workpop_stats$state_pop_count / workpop_stats$total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Export Enriched Master Dataset\n",
    "\n",
    "Write the final enriched dataset to a compressed Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"\\n=== Step 6: Exporting enriched master dataset ===\")\n",
    "cat(\"\\nWriting to Parquet (this may take several minutes)...\\n\")\n",
    "\n",
    "start_time <- Sys.time()\n",
    "\n",
    "query_export <- sprintf(\"\n",
    "COPY (\n",
    "  SELECT * FROM enriched_master\n",
    ") TO '%s' (FORMAT PARQUET, COMPRESSION ZSTD, ROW_GROUP_SIZE 100000)\n",
    "\", OUTPUT_PATH)\n",
    "\n",
    "dbExecute(con, query_export)\n",
    "\n",
    "elapsed_time <- as.numeric(difftime(Sys.time(), start_time, units=\"secs\"))\n",
    "file_size <- file.info(OUTPUT_PATH)$size\n",
    "\n",
    "format_file_size <- function(size_bytes) {\n",
    "  units <- c('B', 'KB', 'MB', 'GB', 'TB')\n",
    "  unit_index <- 1\n",
    "  size <- size_bytes\n",
    "  \n",
    "  while (size >= 1024 && unit_index < length(units)) {\n",
    "    size <- size / 1024\n",
    "    unit_index <- unit_index + 1\n",
    "  }\n",
    "  \n",
    "  sprintf(\"%.1f %s\", size, units[unit_index])\n",
    "}\n",
    "\n",
    "cat(\"\\n✓ Enriched master dataset created!\\n\")\n",
    "cat(sprintf(\"  - Output: %s\\n\", OUTPUT_PATH))\n",
    "cat(sprintf(\"  - Size: %s\\n\", format_file_size(file_size)))\n",
    "cat(sprintf(\"  - Time: %.1f seconds\\n\", elapsed_time))\n",
    "cat(sprintf(\"  - Rows: %s\\n\", format(workpop_stats$total, big.mark=\",\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"\\n\" %+% paste(rep(\"=\", 80), collapse=\"\") %+% \"\\n\")\n",
    "cat(\"ENRICHED MASTER DATASET CREATION COMPLETE\\n\")\n",
    "cat(paste(rep(\"=\", 80), collapse=\"\") %+% \"\\n\\n\")\n",
    "\n",
    "cat(\"Added columns:\\n\")\n",
    "cat(\"  1. SEVIS_ID - Unique identifier (Year + Individual_Key)\\n\")\n",
    "cat(\"  2. IS_STEM - STEM classification based on DHS list\\n\")\n",
    "cat(\"  3. NSF_SUBJ_FIELD_BROAD - NSF broad subject field\\n\")\n",
    "cat(\"  4. CAMPUS_LMA - Campus labor market area\\n\")\n",
    "cat(\"  5. EMPLOYER_LMA - Employer labor market area\\n\")\n",
    "cat(\"  6. CAMPUS_COUNTY - Campus county name\\n\")\n",
    "cat(\"  7. EMPLOYER_COUNTY - Employer county name\\n\")\n",
    "cat(\"  8. EMPLOYER_LMA_WORKPOP_YR - Working population in employer LMA\\n\")\n",
    "cat(\"  9. EMPLOYER_STATE_WORKPOP_YR - Working population in employer state\\n\")\n",
    "\n",
    "cat(\"\\n✓ You can now run create_staging_tables.ipynb to create analysis-ready staging tables.\\n\")\n",
    "\n",
    "# Disconnect\n",
    "dbDisconnect(con, shutdown = TRUE)\n",
    "cat(\"\\n✓ Database connection closed\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Verify the output**: Check that `sevis_f1_enriched_master.parquet` was created successfully\n",
    "2. **Update staging tables notebook**: The `create_staging_tables.ipynb` notebook will be updated to read from this enriched master file\n",
    "3. **Run staging tables**: Execute `create_staging_tables.ipynb` to create analysis-ready staging tables\n",
    "4. **Run analyses**: Use the individual analysis notebooks to explore the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
