{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Create Enriched Master Dataset\n\nThis notebook reads the cleaned yearly CSV files and adds supplemental columns needed for analysis.\n\n**What this does:**\n- Reads all `cleaned_*.csv` files from `../data/cleaned/`\n- Adds supplemental columns (SEVIS_ID, IS_STEM, geographic mappings, etc.)\n- Outputs a single enriched master Parquet file\n\n**Supporting data required:**\n- DHS STEM CIP code list (2024)\n- CIP code to NSF subject field mapping\n- ZIP code to LMA mapping (quarterly, 2010-2024)\n- ZIP code to county mapping (quarterly, 2010-2024)\n- Working population by county (yearly, 2004-2023)\n\n**Run this once** after cleaning the data and before creating staging tables.\n\n**Expected runtime:** 10-30 minutes depending on your machine and data size."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ===== USER CONFIGURATION =====\n\n# Input paths\nRAW_DATA_PATH <- '../data/cleaned/cleaned_*_all.csv'\nSUPPORTING_DATA_DIR <- '../data/supporting'\n\n# Output path\nOUTPUT_PATH <- '../data/sevis_f1_enriched_master.parquet'\n\n# Supporting data files (update these paths as needed)\nDHS_STEM_LIST <- file.path(SUPPORTING_DATA_DIR, 'dhs_stem_cip_code_list_July2024.csv')\nCIP_TO_NSF_MAPPING <- file.path(SUPPORTING_DATA_DIR, 'cip_code_to_nsf_subject_field_mapping.csv')\nZIP_LMA_MAPPING <- file.path(SUPPORTING_DATA_DIR, 'zip_county_lma_quarterly.csv')\nZIP_COUNTY_CROSSWALK <- file.path(SUPPORTING_DATA_DIR, 'HUD_zip_code_to_county_crosswalk_2010-2024.csv')\nWORKING_POP_BY_COUNTY <- file.path(SUPPORTING_DATA_DIR, 'working_pop_by_county_fips_2004-2023.csv')\n\ncat(\"Configuration:\\n\")\ncat(sprintf(\"  Input: %s\\n\", RAW_DATA_PATH))\ncat(sprintf(\"  Output: %s\\n\", OUTPUT_PATH))\ncat(sprintf(\"  Supporting data: %s\\n\", SUPPORTING_DATA_DIR))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(duckdb)\n",
    "library(DBI)\n",
    "\n",
    "# Connect to DuckDB\n",
    "con <- dbConnect(duckdb::duckdb())\n",
    "\n",
    "cat(\"✓ DuckDB connection established\\n\")\n",
    "\n",
    "# Check that supporting data files exist\n",
    "required_files <- c(DHS_STEM_LIST, CIP_TO_NSF_MAPPING, ZIP_LMA_MAPPING, \n",
    "                    ZIP_COUNTY_CROSSWALK, WORKING_POP_BY_COUNTY)\n",
    "\n",
    "cat(\"\\nChecking supporting data files:\\n\")\n",
    "for (f in required_files) {\n",
    "  if (file.exists(f)) {\n",
    "    cat(sprintf(\"  ✓ %s\\n\", basename(f)))\n",
    "  } else {\n",
    "    cat(sprintf(\"  ✗ MISSING: %s\\n\", basename(f)))\n",
    "    stop(sprintf(\"Required file not found: %s\", f))\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create SEVIS_ID\n",
    "\n",
    "Unique identifier combining Year + Individual_Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat(\"\\n=== Step 1: Creating SEVIS_ID ===\")\n",
    "cat(\"\\nReading raw data and creating SEVIS_ID column...\\n\")\n",
    "\n",
    "query_sevis_id <- sprintf(\"\n",
    "CREATE OR REPLACE TEMP TABLE base_data AS\n",
    "SELECT \n",
    "  *,\n",
    "  CONCAT(CAST(Year AS VARCHAR), Individual_Key) AS SEVIS_ID\n",
    "FROM read_csv_auto('%s', union_by_name=true)\n",
    "\", RAW_DATA_PATH)\n",
    "\n",
    "dbExecute(con, query_sevis_id)\n",
    "\n",
    "# Get row count\n",
    "row_count <- dbGetQuery(con, \"SELECT COUNT(*) as count FROM base_data\")$count\n",
    "cat(sprintf(\"✓ Base data loaded: %s rows\\n\", format(row_count, big.mark=\",\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Add IS_STEM Column\n",
    "\n",
    "Marks records as STEM based on DHS STEM CIP code list (considers any major or minor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat(\"\\n=== Step 2: Adding IS_STEM column ===\")\n",
    "cat(\"\\nJoining to DHS STEM CIP code list...\\n\")\n",
    "\n",
    "query_is_stem <- sprintf(\"\n",
    "CREATE OR REPLACE TEMP TABLE with_stem AS\n",
    "SELECT \n",
    "  b.*,\n",
    "  CASE\n",
    "    -- If all CIP fields are missing/blank, keep unknown as NULL\n",
    "    WHEN NULLIF(TRIM(b.Major_1_CIP_Code), '') IS NULL \n",
    "     AND NULLIF(TRIM(b.Major_2_CIP_Code), '') IS NULL \n",
    "     AND NULLIF(TRIM(b.Minor_CIP_Code), '') IS NULL\n",
    "    THEN NULL\n",
    "    -- Otherwise TRUE if any CIP matches the DHS STEM list\n",
    "    ELSE EXISTS (\n",
    "      SELECT 1\n",
    "      FROM (\n",
    "        SELECT UNNEST([b.Major_1_CIP_Code, b.Major_2_CIP_Code, b.Minor_CIP_Code]) AS cip\n",
    "      ) cips\n",
    "      JOIN read_csv_auto('%s') AS stem_list\n",
    "        ON LOWER(REPLACE(TRIM(stem_list.\\\"2020_cip_code\\\"), ' ', '')) \n",
    "         = LOWER(REPLACE(TRIM(cips.cip), ' ', ''))\n",
    "    )\n",
    "  END AS IS_STEM\n",
    "FROM base_data b\n",
    "\", DHS_STEM_LIST)\n",
    "\n",
    "dbExecute(con, query_is_stem)\n",
    "\n",
    "# Get STEM count\n",
    "stem_stats <- dbGetQuery(con, \"\n",
    "  SELECT \n",
    "    COUNT(*) as total,\n",
    "    SUM(CASE WHEN IS_STEM = TRUE THEN 1 ELSE 0 END) as stem_count,\n",
    "    SUM(CASE WHEN IS_STEM IS NULL THEN 1 ELSE 0 END) as unknown_count\n",
    "  FROM with_stem\n",
    "\")\n",
    "\n",
    "cat(sprintf(\"✓ STEM classification complete:\\n\"))\n",
    "cat(sprintf(\"  - STEM: %s (%.1f%%)\\n\", \n",
    "            format(stem_stats$stem_count, big.mark=\",\"),\n",
    "            100 * stem_stats$stem_count / stem_stats$total))\n",
    "cat(sprintf(\"  - Non-STEM: %s (%.1f%%)\\n\", \n",
    "            format(stem_stats$total - stem_stats$stem_count - stem_stats$unknown_count, big.mark=\",\"),\n",
    "            100 * (stem_stats$total - stem_stats$stem_count - stem_stats$unknown_count) / stem_stats$total))\n",
    "cat(sprintf(\"  - Unknown: %s (%.1f%%)\\n\", \n",
    "            format(stem_stats$unknown_count, big.mark=\",\"),\n",
    "            100 * stem_stats$unknown_count / stem_stats$total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Add NSF_SUBJ_FIELD_BROAD Column\n",
    "\n",
    "Maps CIP codes to NSF broad subject fields (based on first major only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat(\"\\n=== Step 3: Adding NSF_SUBJ_FIELD_BROAD column ===\")\n",
    "cat(\"\\nMapping CIP codes to NSF fields...\\n\")\n",
    "\n",
    "# Helper function to normalize CIP codes (MM.mmmm format)\n",
    "query_nsf <- sprintf(\"\n",
    "CREATE OR REPLACE TEMP TABLE with_nsf AS\n",
    "SELECT \n",
    "  w.*,\n",
    "  m.NSF_BROAD_FIELD AS NSF_SUBJ_FIELD_BROAD\n",
    "FROM with_stem w\n",
    "LEFT JOIN (\n",
    "  SELECT DISTINCT\n",
    "    -- Normalize CIP code to MM.mmmm format\n",
    "    CONCAT(\n",
    "      LPAD(REGEXP_EXTRACT(TRIM(CIPCODE_ORIGINAL), '(\\\\d+)', 1), 2, '0'),\n",
    "      '.',\n",
    "      RPAD(COALESCE(REGEXP_EXTRACT(TRIM(CIPCODE_ORIGINAL), '\\\\d+\\\\.(\\\\d+)$', 1), ''), 4, '0')\n",
    "    ) AS cip_normalized,\n",
    "    NSF_BROAD_FIELD\n",
    "  FROM read_csv_auto('%s')\n",
    ") m\n",
    "  ON CONCAT(\n",
    "       LPAD(REGEXP_EXTRACT(TRIM(CAST(w.Major_1_CIP_Code AS VARCHAR)), '(\\\\d+)', 1), 2, '0'),\n",
    "       '.',\n",
    "       RPAD(COALESCE(REGEXP_EXTRACT(TRIM(CAST(w.Major_1_CIP_Code AS VARCHAR)), '\\\\d+\\\\.(\\\\d+)$', 1), ''), 4, '0')\n",
    "     ) = m.cip_normalized\n",
    "\", CIP_TO_NSF_MAPPING)\n",
    "\n",
    "dbExecute(con, query_nsf)\n",
    "\n",
    "# Get NSF field stats\n",
    "nsf_stats <- dbGetQuery(con, \"\n",
    "  SELECT \n",
    "    COUNT(*) as total,\n",
    "    COUNT(NSF_SUBJ_FIELD_BROAD) as mapped_count\n",
    "  FROM with_nsf\n",
    "\")\n",
    "\n",
    "cat(sprintf(\"✓ NSF field mapping complete: %s/%s records mapped (%.1f%%)\\n\",\n",
    "            format(nsf_stats$mapped_count, big.mark=\",\"),\n",
    "            format(nsf_stats$total, big.mark=\",\"),\n",
    "            100 * nsf_stats$mapped_count / nsf_stats$total))\n",
    "\n",
    "# Show top NSF fields\n",
    "top_fields <- dbGetQuery(con, \"\n",
    "  SELECT NSF_SUBJ_FIELD_BROAD, COUNT(*) as count\n",
    "  FROM with_nsf\n",
    "  WHERE NSF_SUBJ_FIELD_BROAD IS NOT NULL\n",
    "  GROUP BY NSF_SUBJ_FIELD_BROAD\n",
    "  ORDER BY count DESC\n",
    "  LIMIT 5\n",
    "\")\n",
    "\n",
    "cat(\"\\nTop 5 NSF fields:\\n\")\n",
    "for (i in 1:nrow(top_fields)) {\n",
    "  cat(sprintf(\"  %d. %s: %s\\n\", i, top_fields$NSF_SUBJ_FIELD_BROAD[i], \n",
    "              format(top_fields$count[i], big.mark=\",\")))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Add Geographic Columns (LMA and County)\n",
    "\n",
    "Maps ZIP codes to Labor Market Areas (LMAs) and counties based on Program End Date quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat(\"\\n=== Step 4: Adding geographic columns (CAMPUS_LMA, EMPLOYER_LMA, CAMPUS_COUNTY, EMPLOYER_COUNTY) ===\")\n",
    "cat(\"\\nThis may take several minutes...\\n\")\n",
    "\n",
    "# First, create a slim ZIP→LMA lookup table\n",
    "cat(\"\\nStep 4a: Creating ZIP→LMA lookup...\\n\")\n",
    "query_lma_lookup <- sprintf(\"\n",
    "CREATE OR REPLACE TEMP TABLE zip_lma_slim AS\n",
    "WITH cleaned AS (\n",
    "  SELECT\n",
    "    CAST(YEAR AS INTEGER) AS year,\n",
    "    CAST(QUARTER AS INTEGER) AS quarter,\n",
    "    SUBSTR(REGEXP_REPLACE(TRIM(zip5), '[^0-9]', ''), 1, 5) AS zip5_norm,\n",
    "    lma_name\n",
    "  FROM read_csv_auto('%s')\n",
    ")\n",
    "SELECT year, quarter, zip5_norm, lma_name\n",
    "FROM cleaned\n",
    "WHERE year IS NOT NULL\n",
    "  AND quarter BETWEEN 1 AND 4\n",
    "  AND LENGTH(zip5_norm) = 5\n",
    "  AND zip5_norm <> '00000'\n",
    "QUALIFY ROW_NUMBER() OVER (\n",
    "  PARTITION BY year, quarter, zip5_norm\n",
    "  ORDER BY lma_name\n",
    ") = 1\n",
    "\", ZIP_LMA_MAPPING)\n",
    "\n",
    "dbExecute(con, query_lma_lookup)\n",
    "lma_count <- dbGetQuery(con, \"SELECT COUNT(*) as count FROM zip_lma_slim\")$count\n",
    "cat(sprintf(\"✓ ZIP→LMA lookup created: %s mappings\\n\", format(lma_count, big.mark=\",\")))\n",
    "\n",
    "# Create ZIP→County lookup table\n",
    "cat(\"\\nStep 4b: Creating ZIP→County lookup...\\n\")\n",
    "query_county_lookup <- sprintf(\"\n",
    "CREATE OR REPLACE TEMP TABLE zip_county_slim AS\n",
    "WITH cw AS (\n",
    "  SELECT\n",
    "    CAST(YEAR AS INTEGER) AS year,\n",
    "    CAST(QUARTER AS INTEGER) AS quarter,\n",
    "    SUBSTR(REGEXP_REPLACE(TRIM(ZIP), '[^0-9]', ''), 1, 5) AS zip5_norm,\n",
    "    COUNTY AS county5\n",
    "  FROM read_csv_auto('%s')\n",
    "),\n",
    "wp AS (\n",
    "  SELECT\n",
    "    LPAD(CAST(CAST(TRIM(CAST(County_LAUS_areacode AS VARCHAR)) AS INTEGER) AS VARCHAR), 5, '0') AS county5,\n",
    "    County_Name_State_Abbreviation\n",
    "  FROM read_csv_auto('%s')\n",
    ")\n",
    "SELECT\n",
    "  cw.year,\n",
    "  cw.quarter,\n",
    "  cw.zip5_norm,\n",
    "  wp.County_Name_State_Abbreviation\n",
    "FROM cw\n",
    "JOIN wp USING (county5)\n",
    "WHERE cw.year IS NOT NULL\n",
    "  AND cw.quarter BETWEEN 1 AND 4\n",
    "  AND LENGTH(cw.zip5_norm) = 5\n",
    "  AND cw.zip5_norm <> '00000'\n",
    "QUALIFY ROW_NUMBER() OVER (\n",
    "  PARTITION BY year, quarter, zip5_norm\n",
    "  ORDER BY County_Name_State_Abbreviation\n",
    ") = 1\n",
    "\", ZIP_COUNTY_CROSSWALK, WORKING_POP_BY_COUNTY)\n",
    "\n",
    "dbExecute(con, query_county_lookup)\n",
    "county_count <- dbGetQuery(con, \"SELECT COUNT(*) as count FROM zip_county_slim\")$count\n",
    "cat(sprintf(\"✓ ZIP→County lookup created: %s mappings\\n\", format(county_count, big.mark=\",\")))\n",
    "\n",
    "# Now join to add all 4 geographic columns\n",
    "cat(\"\\nStep 4c: Joining geographic data to main dataset...\\n\")\n",
    "query_geo <- \"\n",
    "CREATE OR REPLACE TEMP TABLE with_geo AS\n",
    "SELECT \n",
    "  n.*,\n",
    "  lma_campus.lma_name AS CAMPUS_LMA,\n",
    "  lma_employer.lma_name AS EMPLOYER_LMA,\n",
    "  county_campus.County_Name_State_Abbreviation AS CAMPUS_COUNTY,\n",
    "  county_employer.County_Name_State_Abbreviation AS EMPLOYER_COUNTY\n",
    "FROM with_nsf n\n",
    "LEFT JOIN zip_lma_slim lma_campus\n",
    "  ON EXTRACT(YEAR FROM TRY_CAST(n.Program_End_Date AS DATE)) = lma_campus.year\n",
    " AND EXTRACT(QUARTER FROM TRY_CAST(n.Program_End_Date AS DATE)) = lma_campus.quarter\n",
    " AND n.Campus_Zip_Code = lma_campus.zip5_norm\n",
    "LEFT JOIN zip_lma_slim lma_employer\n",
    "  ON EXTRACT(YEAR FROM TRY_CAST(n.Program_End_Date AS DATE)) = lma_employer.year\n",
    " AND EXTRACT(QUARTER FROM TRY_CAST(n.Program_End_Date AS DATE)) = lma_employer.quarter\n",
    " AND n.Employer_Zip_Code = lma_employer.zip5_norm\n",
    "LEFT JOIN zip_county_slim county_campus\n",
    "  ON EXTRACT(YEAR FROM TRY_CAST(n.Program_End_Date AS DATE)) = county_campus.year\n",
    " AND EXTRACT(QUARTER FROM TRY_CAST(n.Program_End_Date AS DATE)) = county_campus.quarter\n",
    " AND n.Campus_Zip_Code = county_campus.zip5_norm\n",
    "LEFT JOIN zip_county_slim county_employer\n",
    "  ON EXTRACT(YEAR FROM TRY_CAST(n.Program_End_Date AS DATE)) = county_employer.year\n",
    " AND EXTRACT(QUARTER FROM TRY_CAST(n.Program_End_Date AS DATE)) = county_employer.quarter\n",
    " AND n.Employer_Zip_Code = county_employer.zip5_norm\n",
    "\"\n",
    "\n",
    "dbExecute(con, query_geo)\n",
    "\n",
    "# Get match rates\n",
    "geo_stats <- dbGetQuery(con, \"\n",
    "  SELECT \n",
    "    COUNT(*) as total,\n",
    "    COUNT(CAMPUS_LMA) as campus_lma_count,\n",
    "    COUNT(EMPLOYER_LMA) as employer_lma_count,\n",
    "    COUNT(CAMPUS_COUNTY) as campus_county_count,\n",
    "    COUNT(EMPLOYER_COUNTY) as employer_county_count\n",
    "  FROM with_geo\n",
    "\")\n",
    "\n",
    "cat(\"\\n✓ Geographic columns added:\\n\")\n",
    "cat(sprintf(\"  - CAMPUS_LMA: %s/%s (%.1f%%)\\n\",\n",
    "            format(geo_stats$campus_lma_count, big.mark=\",\"),\n",
    "            format(geo_stats$total, big.mark=\",\"),\n",
    "            100 * geo_stats$campus_lma_count / geo_stats$total))\n",
    "cat(sprintf(\"  - EMPLOYER_LMA: %s/%s (%.1f%%)\\n\",\n",
    "            format(geo_stats$employer_lma_count, big.mark=\",\"),\n",
    "            format(geo_stats$total, big.mark=\",\"),\n",
    "            100 * geo_stats$employer_lma_count / geo_stats$total))\n",
    "cat(sprintf(\"  - CAMPUS_COUNTY: %s/%s (%.1f%%)\\n\",\n",
    "            format(geo_stats$campus_county_count, big.mark=\",\"),\n",
    "            format(geo_stats$total, big.mark=\",\"),\n",
    "            100 * geo_stats$campus_county_count / geo_stats$total))\n",
    "cat(sprintf(\"  - EMPLOYER_COUNTY: %s/%s (%.1f%%)\\n\",\n",
    "            format(geo_stats$employer_county_count, big.mark=\",\"),\n",
    "            format(geo_stats$total, big.mark=\",\"),\n",
    "            100 * geo_stats$employer_county_count / geo_stats$total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Add Working Population Columns\n",
    "\n",
    "Adds working population data for employer LMA and state (for context/normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat(\"\\n=== Step 5: Adding working population columns ===\")\n",
    "cat(\"\\nUnpivoting working population data...\\n\")\n",
    "\n",
    "# Create unpivoted working population lookup\n",
    "query_workpop <- sprintf(\"\n",
    "CREATE OR REPLACE TEMP TABLE workpop_long AS\n",
    "SELECT\n",
    "  County_Name_State_Abbreviation,\n",
    "  state_name,\n",
    "  CAST(year_col AS INTEGER) AS year,\n",
    "  CASE\n",
    "    WHEN LOWER(TRIM(pop_value)) IN ('missing data', '') THEN NULL\n",
    "    ELSE CAST(REPLACE(TRIM(pop_value), ',', '') AS INTEGER)\n",
    "  END AS working_pop\n",
    "FROM (\n",
    "  SELECT\n",
    "    County_Name_State_Abbreviation,\n",
    "    state_name,\n",
    "    UNNEST([\n",
    "      '2004','2005','2006','2007','2008','2009','2010','2011','2012','2013',\n",
    "      '2014','2015','2016','2017','2018','2019','2020','2021','2022','2023','2024'\n",
    "    ]) AS year_col,\n",
    "    UNNEST([\n",
    "      LMA_WORKING_POP_2004, LMA_WORKING_POP_2005, LMA_WORKING_POP_2006, LMA_WORKING_POP_2007,\n",
    "      LMA_WORKING_POP_2008, LMA_WORKING_POP_2009, LMA_WORKING_POP_2010, LMA_WORKING_POP_2011,\n",
    "      LMA_WORKING_POP_2012, LMA_WORKING_POP_2013, LMA_WORKING_POP_2014, LMA_WORKING_POP_2015,\n",
    "      LMA_WORKING_POP_2016, LMA_WORKING_POP_2017, LMA_WORKING_POP_2018, LMA_WORKING_POP_2019,\n",
    "      LMA_WORKING_POP_2020, LMA_WORKING_POP_2021, LMA_WORKING_POP_2022, LMA_WORKING_POP_2023,\n",
    "      LMA_WORKING_POP_2024\n",
    "    ]) AS pop_value\n",
    "  FROM read_csv_auto('%s')\n",
    ")\n",
    "WHERE year BETWEEN 2004 AND 2024\n",
    "\", WORKING_POP_BY_COUNTY)\n",
    "\n",
    "dbExecute(con, query_workpop)\n",
    "\n",
    "# Aggregate to state level\n",
    "cat(\"Creating state-level aggregates...\\n\")\n",
    "dbExecute(con, \"\n",
    "CREATE OR REPLACE TEMP TABLE workpop_state AS\n",
    "SELECT\n",
    "  state_name,\n",
    "  year,\n",
    "  SUM(working_pop) AS state_working_pop\n",
    "FROM workpop_long\n",
    "WHERE state_name IS NOT NULL\n",
    "GROUP BY state_name, year\n",
    "\")\n",
    "\n",
    "# Join to main dataset\n",
    "cat(\"Joining working population data...\\n\")\n",
    "query_final <- \"\n",
    "CREATE OR REPLACE TEMP TABLE enriched_master AS\n",
    "SELECT \n",
    "  g.*,\n",
    "  wp_lma.working_pop AS EMPLOYER_LMA_WORKPOP_YR,\n",
    "  wp_state.state_working_pop AS EMPLOYER_STATE_WORKPOP_YR\n",
    "FROM with_geo g\n",
    "LEFT JOIN workpop_long wp_lma\n",
    "  ON g.EMPLOYER_COUNTY = wp_lma.County_Name_State_Abbreviation\n",
    " AND EXTRACT(YEAR FROM TRY_CAST(g.Authorization_Start_Date AS DATE)) = wp_lma.year\n",
    "LEFT JOIN workpop_state wp_state\n",
    "  ON g.Employer_State = wp_state.state_name\n",
    " AND EXTRACT(YEAR FROM TRY_CAST(g.Authorization_Start_Date AS DATE)) = wp_state.year\n",
    "\"\n",
    "\n",
    "dbExecute(con, query_final)\n",
    "\n",
    "workpop_stats <- dbGetQuery(con, \"\n",
    "  SELECT \n",
    "    COUNT(*) as total,\n",
    "    COUNT(EMPLOYER_LMA_WORKPOP_YR) as lma_pop_count,\n",
    "    COUNT(EMPLOYER_STATE_WORKPOP_YR) as state_pop_count\n",
    "  FROM enriched_master\n",
    "\")\n",
    "\n",
    "cat(\"\\n✓ Working population columns added:\\n\")\n",
    "cat(sprintf(\"  - EMPLOYER_LMA_WORKPOP_YR: %s/%s (%.1f%%)\\n\",\n",
    "            format(workpop_stats$lma_pop_count, big.mark=\",\"),\n",
    "            format(workpop_stats$total, big.mark=\",\"),\n",
    "            100 * workpop_stats$lma_pop_count / workpop_stats$total))\n",
    "cat(sprintf(\"  - EMPLOYER_STATE_WORKPOP_YR: %s/%s (%.1f%%)\\n\",\n",
    "            format(workpop_stats$state_pop_count, big.mark=\",\"),\n",
    "            format(workpop_stats$total, big.mark=\",\"),\n",
    "            100 * workpop_stats$state_pop_count / workpop_stats$total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Export Enriched Master Dataset\n",
    "\n",
    "Write the final enriched dataset to a compressed Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat(\"\\n=== Step 6: Exporting enriched master dataset ===\")\n",
    "cat(\"\\nWriting to Parquet (this may take several minutes)...\\n\")\n",
    "\n",
    "start_time <- Sys.time()\n",
    "\n",
    "query_export <- sprintf(\"\n",
    "COPY (\n",
    "  SELECT * FROM enriched_master\n",
    ") TO '%s' (FORMAT PARQUET, COMPRESSION ZSTD, ROW_GROUP_SIZE 100000)\n",
    "\", OUTPUT_PATH)\n",
    "\n",
    "dbExecute(con, query_export)\n",
    "\n",
    "elapsed_time <- as.numeric(difftime(Sys.time(), start_time, units=\"secs\"))\n",
    "file_size <- file.info(OUTPUT_PATH)$size\n",
    "\n",
    "format_file_size <- function(size_bytes) {\n",
    "  units <- c('B', 'KB', 'MB', 'GB', 'TB')\n",
    "  unit_index <- 1\n",
    "  size <- size_bytes\n",
    "  \n",
    "  while (size >= 1024 && unit_index < length(units)) {\n",
    "    size <- size / 1024\n",
    "    unit_index <- unit_index + 1\n",
    "  }\n",
    "  \n",
    "  sprintf(\"%.1f %s\", size, units[unit_index])\n",
    "}\n",
    "\n",
    "cat(\"\\n✓ Enriched master dataset created!\\n\")\n",
    "cat(sprintf(\"  - Output: %s\\n\", OUTPUT_PATH))\n",
    "cat(sprintf(\"  - Size: %s\\n\", format_file_size(file_size)))\n",
    "cat(sprintf(\"  - Time: %.1f seconds\\n\", elapsed_time))\n",
    "cat(sprintf(\"  - Rows: %s\\n\", format(workpop_stats$total, big.mark=\",\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat(\"\\n\" %+% paste(rep(\"=\", 80), collapse=\"\") %+% \"\\n\")\n",
    "cat(\"ENRICHED MASTER DATASET CREATION COMPLETE\\n\")\n",
    "cat(paste(rep(\"=\", 80), collapse=\"\") %+% \"\\n\\n\")\n",
    "\n",
    "cat(\"Added columns:\\n\")\n",
    "cat(\"  1. SEVIS_ID - Unique identifier (Year + Individual_Key)\\n\")\n",
    "cat(\"  2. IS_STEM - STEM classification based on DHS list\\n\")\n",
    "cat(\"  3. NSF_SUBJ_FIELD_BROAD - NSF broad subject field\\n\")\n",
    "cat(\"  4. CAMPUS_LMA - Campus labor market area\\n\")\n",
    "cat(\"  5. EMPLOYER_LMA - Employer labor market area\\n\")\n",
    "cat(\"  6. CAMPUS_COUNTY - Campus county name\\n\")\n",
    "cat(\"  7. EMPLOYER_COUNTY - Employer county name\\n\")\n",
    "cat(\"  8. EMPLOYER_LMA_WORKPOP_YR - Working population in employer LMA\\n\")\n",
    "cat(\"  9. EMPLOYER_STATE_WORKPOP_YR - Working population in employer state\\n\")\n",
    "\n",
    "cat(\"\\n✓ You can now run create_staging_tables.ipynb to create analysis-ready staging tables.\\n\")\n",
    "\n",
    "# Disconnect\n",
    "dbDisconnect(con, shutdown = TRUE)\n",
    "cat(\"\\n✓ Database connection closed\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Verify the output**: Check that `sevis_f1_enriched_master.parquet` was created successfully\n",
    "2. **Update staging tables notebook**: The `create_staging_tables.ipynb` notebook will be updated to read from this enriched master file\n",
    "3. **Run staging tables**: Execute `create_staging_tables.ipynb` to create analysis-ready staging tables\n",
    "4. **Run analyses**: Use the individual analysis notebooks to explore the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}